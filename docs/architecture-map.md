Architecture Mental Map: 

AWS, Kubernetes, and Triton connect together. 
The image is ready now â€” it shows AWS EFS storage, Kubernetes cluster orchestration, GPU nodes, PVCs, and the Triton Inference Server pod consuming models.


ðŸ§  Textual Mental Map (Checklist + Flow)
1. AWS Layer
ECR â†’ stores Triton container images.

EFS â†’ shared model repository (resnet50/config.pbtxt + 1/model.onnx).

EC2 GPU Nodes â†’ run Kubernetes worker nodes with GPU acceleration.

2. Kubernetes Layer
PersistentVolume (PV) â†’ points to EFS (fs-xxxx.efs.us-east-1.amazonaws.com:/).

PersistentVolumeClaim (PVC) â†’ bound to PV, mounted into pods at /models.

Helm Chart â†’ defines Deployment, Service, HPA, etc. for Triton.

3. Pod Layer
Triton Pod â†’ runs tritonserver container.

Mounts PVC â†’ /models inside pod = EFS repo.

Init/Sidecar (optional) â†’ sync models or monitor health.

Service â†’ exposes Triton endpoints (HTTP:8000, gRPC:8001, Metrics:8002).

4. Client Layer
Inference Requests â†’ flow through Kubernetes Service â†’ Triton Pod â†’ GPU inference.

Monitoring â†’ Prometheus + Grafana dashboards for observability.
